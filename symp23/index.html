<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">

        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>SoCal NLP Symposium 2023</title>
        <meta name="description" content="Welcome to the Southern California Machine Learning & Natural Language Processing Symposium 2023!">
        <meta name="keywords" content="SoCal,ML,NLP,Symposium,Southern California,Natural Language Processing,Machine Learning,Deep Learning">
        <meta name="author" content="SoCal ML & NLP Symposium Organizers">

        <link rel="icon" href="static/favicon.ico">

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <link rel="stylesheet" href="css/fonts.css">
        <link rel="stylesheet" href="css/custom.css">
    </head>

    <body>
        <div id="header">
            <div class="container">
               <div id="header-desc">
                   <p style="font-size:2.2rem;text-align:center;">SoCal NLP Symposium 2023</p>
                   <p style="font-size:1.3rem;text-align:center;">University of California, Los Angeles | November 17, 2023</p>
                   <!-- <p style="font-size:1.3rem;text-align:center;">Event Livestream <a href="https://youtu.be/hwXA7x5KoCo" style="color:#FF8989;">Here</a> starting 9:00am PST</p> -->
               </div>
            </div>
        </div>

        <div class="container">
            <nav class="navbar navbar-expand-lg navbar-light bg-light rounded">
                <a class="navbar-brand" href="index.html">Welcome</a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#content" aria-controls="navbarsExample09" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <div class="collapse navbar-collapse" id="content">
                    <ul class="navbar-nav mr-auto">
                        <!--<li class="nav-item">-->
                            <!--<a class="nav-link" href="#cfp"><b>Call For Papers</b></a>-->
                        <!--</li>-->
                        <li class="nav-item">
                            <a class="nav-link" href="#venue"><b>Venue</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#schedule"><b>Schedule</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#speaker"><b>Invited Speakers</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#award"><b>Awards</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#paper"><b>Accepted Work</b></a>
                        </li>

                        <li class="nav-item">
                            <a class="nav-link" href="#organizer"><b>Organizers</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#sponsor"><b>Sponsors</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href='#past'><b>Past Symposiums</b></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href='#contact'><b>Contact</b></a>
                        </li>
                    </ul>
                </div>
            </nav>
        </div>

        <p>
		<img src="static/socalnlp_logo.png" class="img-fluid mx-auto d-block" width="250"/>
	</p>

        <div id="welcome" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Welcome</h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <!-- <h5>Event Livestream <a href="https://youtu.be/hwXA7x5KoCo" style="color:#FF8989;">Here</a> starting 9:00am PST</h5> -->
                    <p>The SoCal NLP Symposium aims to bring together students and faculty to promote natural language processing research in the (Southern) California region. <b>The 4th SoCal NLP Symposium will be held at Mong Learning Center, the ground floor of the Engineering VI building at UCLA, Los Angeles, CA</b>.
                    </p>
                    <p>
                    We call for <b>poster presentations</b> by researchers, students, and postdocs that describe ongoing, planned, or completed research projects, including <b>previously published results and negative results</b>. Research in any field applying computational methods to any aspect of human language, from all areas of computer science, linguistics, engineering, neuroscience, social science, information science, and related fields, is welcome. All accepted submissions are non-archival (only paper title and authorship will be revealed in our website) and will be presented as posters.
                    <br><br>
		    <font color="#FF8989">Poster Reminder:</font> The size of the poster board is <strong>30" x 40"</strong>. Please print your poster accordingly. We recommend printing a <strong>24” x 36” poster</strong> in a vertical orientation.
		    </p>
                    <h5>Important Dates</h5>
                    <p>
		      <b>Registration deadline</b>: Nov. 10, 2023 (Friday), 11:59 PM PT <a href="https://www.eventbrite.com/e/socal-nlp-symposium-2023-tickets-732957233817">[Registeration Site]</a><br>
                      <b>Submission deadline</b>: Oct. 23, 2023 (Monday), 11:59 PM PT <a href="https://openreview.net/group?id=SoCalNLP/2023/Symposium">[Submission Portal]</a><br>
		      <b>Acceptance notification</b>: Nov. 1, 2023 (Wednesday)<br>
		      <b>Symposium date</b>: Nov. 17, 2023 (Friday)<br>
                      <b>Submission format</b>: 
					  <ul>
					  <li>If the paper is published in a recent conference or journal, you can directly submit the paper without modification. <strong>Please indicate where the paper is published in the Abstract when submitting the paper</strong>. </li>
					  <li>For papers that have not been previously published, we recommend submitting an extended summary spanning no more than two pages, formatted according to <a href="https://github.com/acl-org/acl-style-files">the ACL guidelines</a>, However, submissions of a longer length will also be considered.</li>
					<li> All submissions are single-blind reviewed. 
					  </ul>
                    </p>   

                </div>
            </div>
        </div>

        <br/>

        <div id="venue" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Venue</h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <p>
                        <b>Date:</b> Nov. 17, 2023<br/>
                        <b>Location:</b> <a href="">Engineering VI building</a> on UCLA <br/><br/>
                        <!--<b><a href="https://youtu.be/hwXA7x5KoCo">Live Stream</a> is available! [TBD] </b> <br/><br/>-->
                        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3291.580549042699!2d-119.84879800252155!3d34.412005835850366!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x80e93f6dfefa0271%3A0x55c533306679b4f6!2sCorwin%20Pavilion!5e0!3m2!1sen!2s!4v1657185901901!5m2!1sen!2s" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> <br/> -->
						<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d13220.00228714143!2d-118.4445256!3d34.0694996!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x80c2bc88bcefb20f%3A0xc622b89fcd2f5d21!2sEngineering%20VI!5e0!3m2!1sen!2sus!4v1696557515537!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> <br/>
                        <!-- <p></p><br/> -->
                        <br/>
			<b>Parking information:</b> The closest parking lot for visitors is located on the top floor of <a href="https://map.ucla.edu/?k=false&id=83929">Parking Structure 8</a> (501 Westwood Plaza, Los Angeles, CA). It will cost $15 for a full day parking. You can pay the fee in pay station or pay-by-phone. 
			If Structure 8 is full, parking structures 2 and 18 are also within walking distance. The detailed information can be found <a href="https://transportation.ucla.edu/campus-parking/visitors">here</a>. <br/>
                    </p>
                </div>
            </div>
        </div>

        <br/>
	 
        <div id="schedule" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Schedule</h4>
                    <hr>
                </div>
            </div>
            <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
              <table>
                  <tr><td><font class="uci-blue">8:30am - 9:15am</font>&nbsp;</td> <td><i>Breakfast & Registration</i></td></tr>
                  <tr><td><font class="uci-blue">9:15am - 9:30am</font>&nbsp;</td> <td><i>Opening Remarks</i></td></tr>
                  <tr><td><font class="uci-blue">9:30am - 10:10am</font>&nbsp;</td> <td><b>Keynote by Aditya Grover (UCLA): <br/><a href="#Aditya">Group Preference Optimization: Few-Shot Alignment of Large Language Models</a></b></td></tr>
                  <tr><td><font class="uci-blue">10:10am - 10:50am</font>&nbsp;</td> <td><b>Invited Talk by Diyi Yang (Stanford): <br/><a href="#Diyi">Human-AI Interaction in the Age of LLMs</a></b></td></tr>
                  <tr><td><font class="uci-blue">10:50am - 11:00am</font>&nbsp;</td> <td><i>Mini Break + Snacks</i></td></tr>
	    	  <tr><td><font class="uci-blue">11:00am - 12:00pm</font>&nbsp;</td> <td>Poster Session 1</td></tr>
                  <tr><td><font class="uci-blue">12:00pm - 1:00pm</font>&nbsp;</td> <td><i>Lunch</i></td></tr>
                  <tr><td><font class="uci-blue">1:00pm - 2:00pm</font>&nbsp;</td> <td>Poster Session 2</td></tr>
	          <tr><td><font class="uci-blue">2:00am - 2:40pm</font>&nbsp;</td> <td><b>Invited Talk by Sean (Xiang) Ren (USC): <br/><a href="#Sean">Reflex or Reflect: When Do Language Tasks Need Slow Reasoning?</a></b></td></tr>
                  <tr><td><font class="uci-blue">2:40pm - 3:20pm</font>&nbsp;</td> <td><b>Invited Talk by Alane Suhr (UCB): <br/><a href="#Alane">Continual Learning of Language Grounding from Situated Human-Agent Interactions</a></b></td></tr>
  		  <tr><td><font class="uci-blue">3:20pm - 4:20pm</font>&nbsp;</td> <td>Poster Session 3</td></tr>
	    	  <tr><td><font class="uci-blue">4:20pm - 4:30pm</font>&nbsp;</td> <td><i>Mini Break + Snacks</i></td></tr>
                  <tr><td><font class="uci-blue">4:30pm - 5:10pm</font>&nbsp;</td> <td><b>Invited Talk by Tatsunori Hashimoto (Stanford): <br/><a href="#Tatsunori">Replicating and Auditing Black-Box Language Models</a></b></td></tr>
                  <tr><td><font class="uci-blue">5:10pm - 5:50pm</font>&nbsp;</td> <td><b>Invited Talk by Dan Roth (Amazon AWS AI / UPenn): <br/><a href="#Dan">LLMs that Reason and Orchestrate</a></b></td></tr>
                  <tr><td><font class="uci-blue">5:50pm - 6:00pm</font>&nbsp;</td> <td><i>Closing Remarks & Awards</i></td></tr>
              </table>
            </div>

        </div>

        <br/>
		
        <div id="speaker" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Invited Speakers</h4>
                    <hr>
                </div>
            </div>
			
            <div class="row">

		<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://www.cis.upenn.edu/~danroth/" target="_block">
                          <img src="https://cogcomp.seas.upenn.edu/images/people/DanRoth.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://www.cis.upenn.edu/~danroth/" target="_block">Dan Roth</a></b></p>
                  <p class="text-center caption caption-role"><b>Distinguished Professor</b></p>
                  <p class="text-center caption caption-role"><b>Computer Science</b></p>
                  <p class="text-center caption caption-loc"><i>Amazon AWS AI / UPenn</i></p>
              </div>
             <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://www.alanesuhr.com/" target="_block">
                          <img src="https://www.alanesuhr.com/photos/photo3-small.png" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://www.alanesuhr.com/" target="_block">Alane Suhr</a></b></p>
                  <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                  <p class="text-center caption caption-role"><b>EECS / BAIR</b></p>
                  <p class="text-center caption caption-loc"><i>UC Berkeley</i></p>
              </div>
		    
             <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://viterbi.usc.edu/directory/faculty/Ren/Xiang" target="_block">
                          <img src="https://viterbi.usc.edu/directory/images/5c5ebb1e5b1caf7b61aab261ed559c54.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://viterbi.usc.edu/directory/faculty/Ren/Xiang" target="_block">Sean (Xiang) Ren</a></b></p>
                  <p class="text-center caption caption-role"><b>Associate Professor</b></p>
                  <p class="text-center caption caption-role"><b>Computer Science</b></p>
                  <p class="text-center caption caption-loc"><i>USC</i></p>
              </div>
		    
           
		<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://thashim.github.io/" target="_block">
                          <img src="https://thashim.github.io/assets/profile-pics/thashim.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://thashim.github.io/" target="_block">Tatsunori Hashimoto</a></b></p>
                  <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                  <p class="text-center caption caption-role"><b>Computer Science</b></p>
                  <p class="text-center caption caption-loc"><i>Stanford</i></p>
              </div>
		<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://cs.stanford.edu/~diyiy/" target="_block">
                          <img src="https://cs.stanford.edu/~diyiy/img/Diyi_Yang.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://cs.stanford.edu/~diyiy/" target="_block">Diyi Yang</a></b></p>
                  <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                  <p class="text-center caption caption-role"><b>Computer Science</b></p>
                  <p class="text-center caption caption-loc"><i>Stanford</i></p>
              </div>
		<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                  <figure style="margin: auto;" class="rounded">
                      <a href="https://aditya-grover.github.io/" target="_block">
                          <img src="https://aditya-grover.github.io/assets/img/Adi.png" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                      </a>
                  </figure>
                  <p class="text-center caption"><b><a href="https://aditya-grover.github.io/" target="_block">Aditya Grover</a></b></p>
                  <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                  <p class="text-center caption caption-role"><b>Computer Science</b></p>
                  <p class="text-center caption caption-loc"><i>UCLA</i></p>
              </div>
		    
            </div>


              <br></br>
                <p>
                    <h5 id="Aditya">Aditya Grover</h5>
                    <b>Title:</b> Group Preference Optimization: Few-Shot Alignment of Large Language Models<br/><br/>
                    <b>Abstract:</b> Many applications of large language models (LLMs), ranging from chatbots to creative writing, require nuanced subjective judgments that can differ significantly across different groups. Existing alignment algorithms can be expensive to align for each group, requiring prohibitive amounts of group-specific preference data and computation for real-world use cases. In this talk, I will introduce Group Preference Optimization (GPO), an alignment framework that steers language models to preferences of individual groups in a few-shot manner. In GPO, we augment the base LLM with an independent transformer module trained to predict the preferences of a group for the LLM generations. We empirically validate the efficacy of GPO through rigorous evaluations using LLMs with varied sizes on three human opinion adaptation tasks. These tasks involve adapting to the preferences of US demographic groups, global countries, and individual users. Our results demonstrate that GPO not only aligns models more accurately but also requires fewer group-specific preferences, and less training and inference computing resources, outperforming existing strategies such as in-context steering and fine-tuning methods. Towards the end of the talk, I will also highlight some surprising observations and open challenges with evaluating language models as a function of their feedback acquisition strategy.<br/><br/>
                    <b>Bio:</b> Aditya Grover is an assistant professor of computer science at UCLA. His goal is to develop efficient machine learning approaches that can interact and reason with limited supervision. He grounds this research in applications in sustainability science. Aditya's research works have been published at top venues including Nature, deployed in production at major technology companies, and covered in popular press venues such as Wall Street Journal and Washington Post. His research has been recognized with a best paper award at NeurIPS, prominent graduate research fellowships and faculty awards (Adobe, Google, Meta, Microsoft, Sony, Simons Institute), the ACM SIGKDD Doctoral Dissertation Award, and the AI Researcher of the Year Award by Samsung, and the Kavli Fellowship from the US National Academy of Sciences. Aditya received his postdoctoral training at UC Berkeley, PhD at Stanford, and bachelors at IIT Delhi, all in computer science. <br/><br/><br/>

                    <h5 id="Diyi">Diyi Yang</h5>
                    <b>Title:</b> Human-AI Interaction in the Age of LLMs<br/><br/>
                    <b>Abstract:</b> Large language models have revolutionized the way humans interact with AI systems, transforming a wide range of fields and disciplines. In this talk, I share two distinct approaches to empowering human-AI interaction using LLMs. The first one explores how large language models transform computational social science, and how human-AI collaboration can reduce costs and improve the efficiency of social science research. The second part looks at social skill learning via LLMs by empowering therapists with LLM-empowered feedback and deliberative practices. These two works demonstrate how human-AI interaction via LLMs can empower individuals and foster positive change. <br/><br/>
                    <b>Bio:</b> Diyi Yang is an assistant professor in the Computer Science Department at Stanford University.  Her research focuses on natural language processing for social impact. She has received multiple best paper awards and recognitions at leading conferences in NLP and HCI. She is a recipient of IEEE AI 10 to Watch (2020), Intel Rising Star Faculty Award (2021),  Microsoft Research Faculty Fellowship (2021),  NSF CAREER Award (2022), and an ONR Young Investigator Award (2023).<br/><br/><br/>

                    <h5 id="Sean">Sean (Xiang) Ren</h5>
                    <b>Title:</b> Reflex or Reflect: When Do Language Tasks Need Slow Reasoning?<br/><br/>
                    <b>Abstract:</b> Large language models, such as GPT-3, excel at generating reflexive responses that mimic human-like language, but they fall short when it comes to complex reasoning that requires slower thinking, deeper reflection and a nuanced interpretation of language. This talk will share two lines of efforts in approaching the above problem. In the first part, I will introduce RICA and RobustRL, two benchmarks that expose language models to logical robustness challenges in language inference. The second part presents our exploration on transferring the Chain-of-Thoughts ability to smaller language models while enhancing model’s logical consistency. We show that a smaller, distilled LM can yield dramatically better task accuracy and rationale-prediction consistency.<br/><br/>
                    <b>Bio:</b> Sean Ren is an Associate Professor, Viterbi Early Career Chair, and Director of the INK Lab at the University of South California. He was previously a research scholar at Stanford and earned his Ph.D. from the University of Illinois Urbana-Champaign. Sean focuses on creating generalizable NLP systems to redefine human-AI collaboration. His research has received several Outstanding Paper Awards at the top AI conferences, an NSF CAREER Award, and research awards from Google, Meta, Amazon, JP Morgan, and Sony. Sean was named Forbes Asia 30 Under 30, and MIT Technology Review Innovators Under 35 (Asia Pacific).<br/><br/><br/>
                    
                    <h5 id="Alane">Alane Suhr</h5>
                    <b>Title:</b> Continual Learning of Language Grounding from Situated Human-Agent Interactions<br/><br/>
                    <b>Abstract:</b> Systems that use language in situated collaborative interactions with human users must reason about language as it is grounded in context. This includes grounding to visual perception and action, but also to the dynamics that arise in multi-turn interactions with human users, wherein users adapt their language and behavior to most effectively collaborate with an agent. While this interactive setting poses a significant challenge, it also opens up new learning opportunities, where a system can continually learn from its interactions with users as they mutually adapt to one another. In this talk, I will discuss a collaborative situated environment that supports studying human-agent language-based interactions, and approaches to continually improve language using agents through these interactions by taking advantage of feedback that is implicitly and explicitly available from these interactions.<br/><br/>
                    <b>Bio:</b> Alane Suhr recently joined EECS and BAIR at UC Berkeley as an Assistant Professor. Alane's work focuses on building language-using systems that communicate with and learn from human users in collaborative, situated interactions. Prior to joining Berkeley, Alane completed a PhD in Computer Science at Cornell University / Cornell Tech and spent a year afterwards as a Young Investigator at the Allen Institute for AI.<br/><br/><br/>

                    <h5 id="Tatsunori">Tatsunori Hashimoto</h5>
                    <b>Title:</b> Replicating and Auditing Black-Box Language Models<br/><br/>
                    <b>Abstract:</b> Advances in large language models have brought about exciting advancements in capabilities, but the commercialization of this technology has led to an increasing loss of transparency. State-of-the-art language models effectively operate as black boxes, with many things unknown about their training algorithms, data annotators, and pertaining data.
			I will cover a trio of recent works from my group that attempt to help us understand each of these components by replicating the RLHF training process (AlpacaFarm), probing LMs to identify whose opinions are being reflected in pretraining and RLHF data (OpinionQA), and providing provable guarantees of test set contamination in black-box language models.
		    <br/><br/>
                    <b>Bio:</b> Tatsunori Hashimoto is an Assistant Professor in the Computer Science Department at Stanford University. He is a member of the statistical machine learning and natural language processing groups at Stanford, and his research uses tools from statistics to make machine learning systems more robust and trustworthy — especially in complex systems such as large language models. He is a Kavli fellow, a Sony and Amazon research award winner, and his work has been recognized with best paper awards at ICML and CHI.
			Before becoming an Assistant Professor, he was a postdoctoral researcher at Stanford with Percy Liang and John Duchi and received his Ph.D. from MIT under the supervision of Tommi Jaakkola and David Gifford.
		    <br/><br/><br/>

                    <h5 id="Dan">Dan Roth</h5>
                    <b>Title:</b> LLMs that Reason and Orchestrate<br/><br/>
                    <b>Abstract:</b> The rapid progress made over the last few years in generating linguistically coherent natural language has blurred, in the mind of many, the difference between natural language generation, understanding, and the ability to reason with respect to the world. Nevertheless, robust support of high-level decisions that depend on natural language understanding, and one that requires dealing with “truthfulness” are still beyond our capabilities, partly since most of these tasks are very sparse, often require grounding, and may depend on new types of supervision signals. 
			<br/>I will discuss some of the challenges underlying reasoning and argue that we should focus on LLMs as orchestrators – coordinating and managing multiple models, applications, and services, as a way to execute complex tasks and processes. I will discuss some of the challenges and present some of our work in this space, focusing on supporting task decomposition and planning. 
 		    <br/><br/>
                    <b>Bio:</b> Dan Roth is the Eduardo D. Glandt Distinguished Professor at the Department of Computer and Information Science, University of Pennsylvania, a VP/Distinguished Scientist at AWS AI Labs, and a Fellow of the AAAS, the ACM, AAAI, and the ACL. 
			In 2017 Roth was awarded the John McCarthy Award, the highest award the AI community gives to mid-career AI researchers. Roth was recognized “for major conceptual and theoretical advances in the modeling of natural language understanding, machine learning, and reasoning.”
                </p>
        </div>
        <br/>


        <div id="award" class="container" align="justify">
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Awards</h4>
                    <hr>
            </div>
          </div>
	
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
              <li>Best Paper presented by SAP<b><font class="uci-blue">Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models</font></b></br>Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models (UCR).</li>
              <li>Best Published Paper presented by Amazon-UCLA Science Hub<b><font class="uci-blue">ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings</font></b></br>Shibo Hao, Tianyang Liu, Zhen Wang, Zhiting Hu (UCSD/MBZUAI).</li>
              <li>Best Theme Paper on trustworthy NLP presented by Capital One:  <b><font class="uci-blue">Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models</font></b></br>Deqing Fu, Tian-qi Chen, Robin Jia, Vatsal Sharan (USC).</li>
            </div>
          </div>
        </div>

        <br/>

        <div id="paper" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Accepted Papers</h4>
                    <hr>
                </div>
            </div>

            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h5> Poster Session #1 (11:00am - 12:00pm)</h5>
                    <p><ol start="1">
<li><b><font class="uci-blue">FairGraph: Automated Graph Debiasing with Gradient Matching</font></b> <br>Yezi Liu</li>
<li><b><font class="uci-blue">KPEval: Towards Fine-grained Semantic-based Evaluation of Keyphrase Extraction and Generation Systems</font></b> <br>Di Wu, Da Yin, Kai-Wei Chang</li>
<li><b><font class="uci-blue">Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models</font></b> <br>Hritik Bansal, John Dang, Aditya Grover</li>
<li><b><font class="uci-blue">Controllable Pareto Trade-off between Fairness and Accuracy</font></b> <br>Yongkang Du, Jieyu Zhao, Yijun Yang, Tianyi Zhou</li>
<li><b><font class="uci-blue">Revisiting the Architectures like Pointer Networks to Efficiently Improve the Next Word Distribution, Summarization Factuality, and Beyond</font></b> <br>Haw-Shiuan Chang, Zonghai Yao, Alolika Gon, hong yu, Andrew McCallum</li>
<li><b><font class="uci-blue">White-Box Multi-Objective Adversarial Attack on Dialogue Generation</font></b> <br>Yufei Li, Zexin Li, yingfan gao, Cong Liu</li>
<li><b><font class="uci-blue">Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data</font></b> <br>Yufei Li, Xiao Yu, Yanchi Liu, Haifeng Chen, Cong Liu</li>
<li><b><font class="uci-blue">ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation</font></b> <br>Yangyi Chen, Xingyao Wang, Manling Li, Derek Hoiem, Heng Ji</li>
<li><b><font class="uci-blue">BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions</font></b> <br>Wenbo Hu</li>
<li><b><font class="uci-blue">Non-Sequential Graph Script Induction via Multimedia Grounding</font></b> <br>Yu Zhou, Sha Li, Manling Li, Xudong Lin, Shih-Fu Chang, Mohit Bansal, Heng Ji</li>
<li><b><font class="uci-blue">DOES VIDEO SUMMARIZATION REQUIRE VIDEOS? QUANTIFYING THE EFFECTIVENESS OF LANGUAGE IN VIDEO SUMMARIZATION</font></b> <br>Yoonsoo Nam, Adam Lehavi, Daniel Yang, Digbalay Bose, Swabha Swayamdipta, Shrikanth Narayanan</li>
<li><b><font class="uci-blue">Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting</font></b> <br>William P Hogan, Jiacheng Li, Jingbo Shang</li>
<li><b><font class="uci-blue">Exploring the Relationship Between Model Architecture and In-Context Learning Ability</font></b> <br>Ivan Lee, Nan Jiang, Taylor Berg-Kirkpatrick</li>
<li><b><font class="uci-blue">How Should We Represent Dialog Acts to Leverage Pretrained Natural Language Generators?</font></b> <br>Alain Vazquez Risco, Asier Lopez Zorrilla, María Inés Torres Barañano</li>
<li><b><font class="uci-blue">Interpretable Diffusion via Information Decomposition</font></b> <br>Xianghao Kong, Ollie Liu, Han Li, Dani Yogatama, Greg Ver Steeg</li>
<li><b><font class="uci-blue">Zero-Shot Detection of Machine-Generated Codes</font></b> <br>Xianjun Yang, Kexun Zhang, Haifeng Chen, Linda Ruth Petzold, William Yang Wang, Wei Cheng</li>
<li><b><font class="uci-blue">Harmful Speech Detection by Large Language Models Contains Gender-Queer Dialect Bias</font></b> <br>Rebecca Dorn, Lee Kezar, Negar Mokhberian, Fred Morstatter, Kristina Lerman</li>
<li><b><font class="uci-blue">Automated Data Analysis Through Multi-Turn Code Generation</font></b> <br>Xueqing Wu, Rui Zheng, Nanyun Peng, Kai-Wei Chang, Haoran Huang</li>
<li><b><font class="uci-blue">Robust Natural Language Understanding with Residual Attention Debiasing</font></b> <br>Fei Wang, James Y. Huang, Tianyi Yan, Wenxuan Zhou, Muhao Chen</li>
<li><b><font class="uci-blue">Certified Robustness for Large Language Models with Self-Denoising</font></b> <br>Zhen Zhang, Bairu Hou</li>
<li><b><font class="uci-blue">Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis</font></b> <br>Qiucheng Wu, Jiabao Ji</li>
<li><b><font class="uci-blue">Language Models Meet World Models: Embodied Experiences Enhance Language Models</font></b> <br>Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, Zhiting Hu</li>
<li><b><font class="uci-blue">The Bias Amplification Paradox in Text-to-Image Generation</font></b> <br>Preethi Seshadri, Sameer Singh, Yanai Elazar</li>
<li><b><font class="uci-blue">Gender Biases in Automatic Evaluation Metrics for Image Captioning</font></b> <br>Haoyi Qiu, Zi-Yi Dou, Tianlu Wang, Asli Celikyilmaz, Nanyun Peng</li>
<li><b><font class="uci-blue">Zero-shot Faithful Factual Error Correction</font></b> <br>Kung-Hsiang Huang, Hou Pong Chan, Heng Ji</li>
<li><b><font class="uci-blue">Group Preference Optimization: Few-Shot Alignment of Large Language Models</font></b> <br>Siyan Zhao, John Dang, Aditya Grover</li>
<li><b><font class="uci-blue">Contextual Label Projection for Cross-Lingual Structured Prediction</font></b> <br>Tanmay Parekh, I-Hung Hsu, Kuan-Hao Huang, Kai-Wei Chang, Nanyun Peng</li>
<li><b><font class="uci-blue">A Causal View of Entity Bias in (Large) Language Models</font></b> <br>Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen</li>
<li><b><font class="uci-blue">Intrepretability in Machine Translation Models with Controlled Generation capabilities</font></b> <br>Priyesh Vakharia, Ian Lane, Leilani H. Gilpin</li>
<li><b><font class="uci-blue">Neural-symbolic Table Question Answering through Table Augmentation</font></b> <br>Yujian Liu</li>
<li><b><font class="uci-blue">DecompX: Explaining Transformers Decisions by Propagating Token Decomposition</font></b> <br>Ali Modarressi, Mohsen Fayyaz, Ehsan Aghazadeh, Yadollah Yaghoobzadeh, Mohammad Taher Pilehvar</li>
<li><b><font class="uci-blue">I'm not Racist but…: Discovering Bias in the Internal Knowledge of Large Language Models</font></b> <br>Abel Salinas, Louis Penafiel, Robert McCormack, Fred Morstatter</li>
<li><b><font class="uci-blue">Open-Domain Text Evaluation via Contrastive Distribution Methods</font></b> <br>Sidi Lu, Tianlu Wang, Asli Celikyilmaz, Nanyun Peng</li>
<li><b><font class="uci-blue">Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation</font></b> <br>Da Yin, Xiao Liu, Fan Yin, Ming Zhong, Hritik Bansal, Jiawei Han, Kai-Wei Chang</li>
<li><b><font class="uci-blue">PHOTOSWAP: Personalized Subject Swapping in Images</font></b> <br>Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, HE Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang</li>
<li><b><font class="uci-blue">Event Linking with an Event-Centric View</font></b> <br>Zihan Xue, I-Hung Hsu, Nilay Pochhi, Sahil Bansal, Jayanth Srinivasa, Nanyun Peng</li>
<li><b><font class="uci-blue">Continual Dialogue State Tracking via Example-Guided Question Answering</font></b> <br>Hyundong Justin Cho, Andrea Madotto, Zhaojiang Lin, Khyathi Chandu, Satwik Kottur, Jing Xu, Jonathan May, Chinnadhurai Sankar</li>
<li><b><font class="uci-blue">Multilingual Language Models are not Multicultural: A Case Study in Emotion</font></b> <br>Shreya Havaldar</li>
<li><b><font class="uci-blue">Context-aware Event Forecasting via Graph Disentanglement</font></b> <br>Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, Tat-Seng Chua</li>
<li><b><font class="uci-blue">Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering</font></b> <br>Wang Zhu, Jesse Thomason, Robin Jia</li>
<li><b><font class="uci-blue">Challenges in Context-Aware Neural Machine Translation</font></b> <br>Linghao Jin, Jacqueline He, Jonathan May, Xuezhe Ma</li>
<li><b><font class="uci-blue">SearchVQA: Visual Reasoning through Reliable VQA Use</font></b> <br>Tejas Srinivasan, Jack Hessel, Tanmay Gupta, Bill Yuchen Lin, Yejin Choi, Jesse Thomason, Khyathi Chandu</li>
<li><b><font class="uci-blue">Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs</font></b> <br>Zijie Huang, Daheng Wang, Binxuan Huang, Chenwei Zhang, Jingbo Shang, Yan Liang, Zhengyang Wang, Xian Li, Christos Faloutsos, Yizhou Sun, Wei Wang</li>
<li><b><font class="uci-blue">SCIBENCH: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models</font></b> <br>Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R Loomba, Shichang Zhang, Yizhou Sun, Wei Wang</li>
<li><b><font class="uci-blue">Prompt Engineering a Prompt Engineer</font></b> <br>Qinyuan Ye, Mohamed Ahmed, Reid Pryzant, Fereshte Khani</li>
<li><b><font class="uci-blue">LayoutGPT: Compositional Visual Planning and Generation with Large Language Models</font></b> <br>Weixi Feng, Wanrong Zhu, Tsu-Jui Fu, Varun Jampani, Arjun Reddy Akula, Xuehai He, S Basu, Xin Eric Wang, William Yang Wang</li>
<li><b><font class="uci-blue">Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection</font></b> <br>Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin</li>
<li><b><font class="uci-blue">Estimating Large Language Model Capabilities without Labeled Test Data</font></b> <br>Harvey Yiyun Fu, Qinyuan Ye, Albert Xu, Xiang Ren, Robin Jia</li>
<li><b><font class="uci-blue">Text Alignment Is An Efficient Unified Model for Massive NLP Tasks</font></b> <br>Yuheng Zha, Yichi Yang, Ruichen Li, Zhiting Hu</li>
<li><b><font class="uci-blue">Creating a Parallel Corpus for a Low-Resource, Indigenous Language: Muisca-to-Spanish</font></b> <br>Aryan Gulati, Leslie Moreno, Aditya Kumar, Abhinav Gupta</li>
<li><b><font class="uci-blue">Large Language Models can Learn Rules</font></b> <br>Zhaocheng Zhu, Yuan Xue, Xinyun Chen, Denny Zhou, Jian Tang, Dale Schuurmans, Hanjun Dai</li>
<li><b><font class="uci-blue">Primacy Effect of ChatGPT</font></b> <br>Yiwei Wang, Yujun Cai, Muhao Chen, Yuxuan Liang, Bryan Hooi</li>


                    </ol></p>

                    <h5> Poster Session #2 (1:00pm - 2:00pm)</h5>
                    <p><ol start="53">
                    <li><b><font class="uci-blue">From Text to Tactic: Evaluating LLMs Playing the Game of Avalon</font></b> <br>Jonathan Light, Min Cai, Sheng Shen, Ziniu Hu</li>
<li><b><font class="uci-blue">VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use</font></b> <br>Yonatan Bitton, Hritik Bansal, Jack Hessel, Rulin Shao, Wanrong Zhu, Anas Awadalla, Joshua P Gardner, Rohan Taori, Ludwig Schmidt</li>
<li><b><font class="uci-blue">Temporal Knowledge Graph Forecasting Using In-Context Learning</font></b> <br>Dong-Ho Lee, Kian Ahrabian, Woojeong Jin, Fred Morstatter, Jay Pujara</li>
<li><b><font class="uci-blue">Analyzing Norm Violations in Live-Stream Chat</font></b> <br>Jihyung Moon, Dong-Ho Lee, Hyundong Justin Cho, Woojeong Jin, Chan Young Park, Minwoo Kim, Jonathan May, Jay Pujara, Sungjoon Park</li>
<li><b><font class="uci-blue">CASA: Causality-driven Argument Sufficiency Assessment</font></b> <br>Xiao Liu, Yansong Feng, Kai-Wei Chang</li>
<li><b><font class="uci-blue">From Shortcuts to Triggers: Backdoor Defense with Denoised PoE</font></b> <br>Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen</li>
<li><b><font class="uci-blue">Learn Your Tokens: Word-Pooled Tokenization for Language Modeling</font></b> <br>Avijit Thawani, Saurabh Ghanekar, Xiaoyuan Zhu, Jay Pujara</li>
<li><b><font class="uci-blue">Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path</font></b> <br>Zilong Wang, Jingbo Shang</li>
<li><b><font class="uci-blue">Can LLM Replace Stack Overflow? A Study on Robustness and Reliability of Large Language Model Code Generation</font></b> <br>Li Zhong, Zilong Wang</li>
<li><b><font class="uci-blue">Selective Perception: Learning Concise State Descriptions for Language Model Actors</font></b> <br>Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, JB Lanier, Pierre Baldi, Roy Fox, Sameer Singh</li>
<li><b><font class="uci-blue">Probing Ideological Stances of Organically-formed Online Communities</font></b> <br>Zihao He, Ashwin Rao, Siyi Guo, Negar Mokhberian, Kristina Lerman</li>
<li><b><font class="uci-blue">Capturing Perspectives of Sparse Annotators in Subjective Learning Tasks</font></b> <br>Negar Mokhberian, Myrl G Marmarelis, Frederic Rene Hopp, Fred Morstatter, Kristina Lerman</li>
<li><b><font class="uci-blue">Cross-lingual Continual Learning</font></b> <br>Meryem M'hamdi, Xiang Ren, Jonathan May</li>
<li><b><font class="uci-blue">Effect of Geometry on Graph Neural Networks</font></b> <br>Xinyue Cui, Praveen Bandla, Rishi Sonthalia</li>
<li><b><font class="uci-blue">ClinScope Corpus - Clinical Notes Annotated for Hedge and Negation</font></b> <br>Lisa Chen, Paea LePendu</li>
<li><b><font class="uci-blue">ED-FAITH: Evaluating Dialogue Summarization on Faithfulness</font></b> <br>Sicong Huang, Asli Celikyilmaz, Haoran Li</li>
<li><b><font class="uci-blue">Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models</font></b> <br>Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, Michael Lyu</li>
<li><b><font class="uci-blue">A Data Fusion Framework for Multi-Domain Morality Learning</font></b> <br>Siyi Guo, Negar Mokhberian, Kristina Lerman</li>
<li><b><font class="uci-blue">Joint Speech Transcription and Translation: Pseudo-Labeling with Out-of-Distribution Data</font></b> <br>Mozhdeh Gheini, Tatiana Likhomanenko, Matthias Sperber, Hendra Setiawan</li>
<li><b><font class="uci-blue">A New Approach to Decomposing Uncertainty Tailored for Large Language Models</font></b> <br>Bairu Hou</li>
<li><b><font class="uci-blue">BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs’ Generation</font></b> <br>Yufei Tian, Felix Zhang, Nanyun Peng</li>
<li><b><font class="uci-blue">ToolDec: Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State Decoding</font></b> <br>Kexun Zhang, Hongqiao Chen, Lei Li, William Yang Wang</li>
<li><b><font class="uci-blue">MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models</font></b> <br>Deepak Nathani</li>
<li><b><font class="uci-blue">Less than One-shot: Named Entity Recognition via Extremely Weak Supervision</font></b> <br>Letian Peng, Zihan Wang, Jingbo Shang</li>
<li><b><font class="uci-blue">Automatic Evaluation of Question Under Discussion Discourse Parsers</font></b> <br>Ashima Suvarna, Xiao Liu, Tanmay Parekh, Kai-Wei Chang, Nanyun Peng</li>
<li><b><font class="uci-blue">Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy</font></b> <br>Yu Fu, Deyi Xiong, Yue Dong</li>
<li><b><font class="uci-blue">Inverse Reinforcement Learning for Text Summarization</font></b> <br>Yu Fu, Deyi Xiong, Yue Dong</li>
<li><b><font class="uci-blue">OCTOPUS: Open-vocabulary Content Tracking and Object Placement Using Semantic Understanding in Mixed Reality</font></b> <br>Luke Yoffe, Aditya Sharma, Tobias Hollerer</li>
<li><b><font class="uci-blue">Coverage-based Example Selection for In-Context Learning</font></b> <br>Shivanshu Gupta, Matt Gardner, Sameer Singh</li>
<li><b><font class="uci-blue">Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN</font></b> <br>Niloofar Mireshghallah, Nikolai Vogler, Junxian He, Omar Florez, Ahmed El-Kishky, Taylor Berg-Kirkpatrick</li>
<li><b><font class="uci-blue">A Multimodal Benchmark of Speech, Gaze, and Sketches for Detecting Alzheimer's disease and related dementias</font></b> <br>Leticia Leonor Pinto Alva, Jesse Thomason, Maja Mataric, Leslie Moreno, Gwen Bradforth, Riley Ashford, Cecily Chung</li>
<li><b><font class="uci-blue">Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought</font></b> <br>Vaishnavi Himakunthala, Andy Ouyang, Daniel Philip Rose, Ryan He, Alex Mei, Yujie Lu, Chinmay Sonar, Michael Saxon, William Yang Wang</li>
<li><b><font class="uci-blue">LegalDiscourse: Interpreting When Laws Apply and Who They Affect</font></b> <br>Alexander Spangher, Te-Lin Wu, Zihan Xue, Mark Hansen, Nanyun Peng, Jonathan May</li>
<li><b><font class="uci-blue">Tracking the Newsworthiness of Public Documents</font></b> <br>Alexander Spangher, Nicholas Diakopoulos, Nanyun Peng, Serdar Tumgoren, Ben Welsh, Emilio Ferrara, Jonathan May</li>
<li><b><font class="uci-blue">Negotiation Agents with Interpretable Strategic Planning: Synergy of LLMs and Reinforcement Learning-Based Steering</font></b> <br>Ian Wu, Yu Rong, Kushal Chawla, Gale Lucas, Jonathan Gratch</li>
<li><b><font class="uci-blue">BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models</font></b> <br>Rafal Dariusz Kocielnik, Shrimai Prabhumoye, Vivian L Zhang, Roy Luoyao Jiang, R. Michael Alvarez, Anima Anandkumar</li>
<li><b><font class="uci-blue">Are models biased on text without gender-related language?</font></b> <br>Catarina G Belém, Preethi Seshadri, Yasaman Razeghi, Sameer Singh</li>
<li><b><font class="uci-blue">Characterizing Attitudes Towards Homelessness on Social Media</font></b> <br>Jaspreet Ranjit, Rebecca Dorn, Olga Koumoundouros, Laura Petry, Eric Rice, Swabha Swayamdipta</li>
<li><b><font class="uci-blue">Large Language Models Can Be Good Privacy Protection Learners</font></b> <br>Yijia Xiao, Yiqiao Jin, Yushi Bai, Yue Wu, Xianjun Yang, Xiao Luo, Wenchao Yu, Xujiang Zhao, Yanchi Liu, Quanquan Gu, Haifeng Chen, Wei Wang, Wei Cheng</li>
<li><b><font class="uci-blue">SemStamp: A Semantic Watermark With Paraphrastic Robustness For Text Generation</font></b> <br>Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, Yulia Tsvetkov</li>
<li><b><font class="uci-blue">Privacy-Preserving Language Model Inference with Instance Obfuscation</font></b> <br>Yixiang Yao, Fei Wang, Srivatsan Ravi, Muhao Chen</li>
<li><b><font class="uci-blue">How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench</font></b> <br>Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, Robin Jia</li>
<li><b><font class="uci-blue">Have I been trained on? Supporting the right to opt-out of LLMs</font></b> <br>Ryan Wang, Johnny Wei, Robin Jia</li>
<li><b><font class="uci-blue">LLM still cannot play like human! Challenges of LLM's strategic playing in a game environment</font></b> <br>Ziyi Liu, Pei Zhou, Jieyu Zhao</li>
<li><b><font class="uci-blue">PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization</font></b> <br>Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, Zhiting Hu</li>
<li><b><font class="uci-blue">Multilingual Conceptual Coverage in Text-to-Image Models</font></b> <br>Michael Saxon, William Yang Wang</li>
<li><b><font class="uci-blue">NEUROFORMER: MULTIMODAL AND MULTITASK GENERATIVE PRETRAINING FOR BRAIN DATA</font></b> <br>Antonis Antoniades, Yiyi Yu, Joe S Canzano, William Yang Wang, Spencer Smith</li>
<li><b><font class="uci-blue">Evaluating Mathematical Reasoning in Visual Contexts with MathVista: A Study of GPT-4V, Bard, and Other Models</font></b> <br>Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, Jianfeng Gao</li>
<li><b><font class="uci-blue">Defining Success for Localization of Memorized Data in LLMs</font></b> <br>Ting-Yun Chang, Robin Jia, Jesse Thomason</li>
<li><b><font class="uci-blue">“Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in LLM-Generated Reference Letters</font></b> <br>Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, Nanyun Peng</li>
<li><b><font class="uci-blue">AGent: A Novel Pipeline for Automatically Creating Unanswerable Questions</font></b> <br>Son Quoc Tran, Gia-Huy Hoang Do, Phong Nguyen-Thuan Do, Matt Kretchmar, Xinya Du</li>
<li><b><font class="uci-blue">Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models</font></b> <br>Deqing Fu, Tian-qi Chen, Robin Jia, Vatsal Sharan</li>

                    </ol></p>

		    <h5> Poster Session #3 (3:20pm - 4:20pm)</h5>
                    <p><ol start="105">
                    <li><b><font class="uci-blue">Closing the Curious Case of Neural Text Degeneration</font></b> <br>Matthew Finlayson, John Hewitt, Alexander Koller, Swabha Swayamdipta, Ashish Sabharwal</li>
<li><b><font class="uci-blue">Error Detection on Knowledge Graphs with Triple Embedding</font></b> <br>Yezi Liu, Qinggang Zhang, Mengnan Du, Xiao Huang, Xia Hu</li>
<li><b><font class="uci-blue">Exploring Distributional Shifts in Large Language Models for Code Analysis</font></b> <br>Shushan Arakelyan, Rocktim Jyoti Das, Yi Mao, Xiang Ren</li>
<li><b><font class="uci-blue">Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data</font></b> <br>Alon Albalak, Colin Raffel, William Yang Wang</li>
<li><b><font class="uci-blue">A Study on Linearizing Structured Data:  Insights from Text-to-SQL</font></b> <br>Yutong Shao, Ndapa Nakashole</li>
<li><b><font class="uci-blue">How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model</font></b> <br>Michael Hanna, Ollie Liu, Alexandre VariengienShow details</li>
<li><b><font class="uci-blue">AVIS: Autonomous Visual Information Seeking with Large Language Model Agent</font></b> <br>Ziniu Hu</li>
<li><b><font class="uci-blue">Will the Prince Get True Love’s Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts</font></b> <br>Christina A Chance, Da Yin, Dakuo Wang, Kai-Wei Chang</li>
<li><b><font class="uci-blue">The Impacts of Unanswerable Questions on the Robustness of Machine Reading Comprehension Models</font></b> <br>Son Quoc Tran, Phong Nguyen-Thuan Do, Uyen Le, Matt Kretchmar</li>
<li><b><font class="uci-blue">Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models</font></b> <br>Erfan Shayegani, Yue Dong, Nael Abu-Ghazaleh</li>
<li><b><font class="uci-blue">SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples</font></b> <br>Deqing Fu, Ameya Godbole, Robin Jia</li>
<li><b><font class="uci-blue">Alt-Text with Context: Improving Accessibility for Images on Twitter</font></b> <br>Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor Berg-Kirkpatrick</li>
<li><b><font class="uci-blue">Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge</font></b> <br>Te-Lin Wu, Yu Zhou, Nanyun Peng</li>
<li><b><font class="uci-blue">Domain-specific Medical Vision-Language Pre-Training: A Dataset for Brain Diseases</font></b> <br>Masoud Monajatipoor, Zi-Yi Dou, Aichi Chien, Nanyun Peng, Kai-Wei Chang</li>
<li><b><font class="uci-blue">Backtracking Mathematical Reasoning of Language Models to the Pretraining Data</font></b> <br>Yasaman Razeghi, Hamish Ivison, Sameer Singh, Yanai Elazar</li>
<li><b><font class="uci-blue">CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation</font></b> <br>Minzhi Li, Taiwei Shi, Caleb Ziems, Min-Yen Kan, Nancy F. Chen, Zhengyuan Liu, Diyi Yang</li>
<li><b><font class="uci-blue">MISGENDERED: Limits of Large Language Models in Understanding</font></b> <br>Tamanna Hossain, Sunipa Dev, Sameer Singh</li>
<li><b><font class="uci-blue">Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models</font></b> <br>Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Jianfeng Gao</li>
<li><b><font class="uci-blue">Look-back Decoding for Open-Ended Text Generation</font></b> <br>Nan Xu, Chunting Zhou, Asli Celikyilmaz, Xuezhe Ma</li>
<li><b><font class="uci-blue">Mitigating Label Biases for In-context Learning</font></b> <br>Yu Fei, Yifan Hou, Zeming Chen, Antoine Bosselut</li>
<li><b><font class="uci-blue">Exploring Training Objectives for Passage-level Differentiable Search Indexing</font></b> <br>Man Luo</li>
<li><b><font class="uci-blue">Red Teaming Language Model Detectors with Language Models</font></b> <br>Zhouxing Shi, Yihan Wang, Fan Yin, Xiangning Chen, Kai-Wei Chang, Cho-Jui Hsieh</li>
<li><b><font class="uci-blue">Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models</font></b> <br>Yiyuan Li, Rakesh R Menon, Sayan Ghosh, Shashank Srivastava</li>
<li><b><font class="uci-blue">UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition</font></b> <br>Wenxuan Zhou, Sheng Zhang, Yu Gu, Muhao Chen, Hoifung Poon</li>
<li><b><font class="uci-blue">Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks</font></b> <br>Po-Nien Kung, Fan Yin, Di Wu, Kai-Wei Chang, Nanyun Peng</li>
<li><b><font class="uci-blue">R2H: Building Multimodal Navigation Helpers that Respond to Help Requests</font></b> <br>Yue Fan, Jing Gu, Kaizhi Zheng, Xin Eric Wang</li>
<li><b><font class="uci-blue">Expanding the Study of Bias in Sentiment Analysis: Investigating Intersectionality and Cross-Linguistic Biases</font></b> <br>Casandra Rusti, Omneya Sultan</li>
<li><b><font class="uci-blue">ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation</font></b> <br>Kaiwen Zhou, Kaizhi Zheng, Connor Pryor, Yilin Shen, Hongxia Jin, Lise Getoor, Xin Eric Wang</li>
<li><b><font class="uci-blue">Estimating Causal Effects of Text Interventions</font></b> <br>Myrl G Marmarelis, Siyi Guo, Fred Morstatter, Kristina Lerman</li>
<li><b><font class="uci-blue">Accelerating Diffusion Models for Zero-Shot Classification</font></b> <br>Xuehai He, Xin Eric Wang</li>
<li><b><font class="uci-blue">Making Large Language Models Better Data Creators</font></b> <br>Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryen W White, Sujay Kumar Jauhar</li>
<li><b><font class="uci-blue">Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models</font></b> <br>Alfonso Amayuelas</li>
<li><b><font class="uci-blue">CausalDialogue: Modeling Utterance-level Causality in Conversations</font></b> <br>Yi-Lin Tuan, Alon Albalak, Wenda Xu, Michael Saxon, Connor Pryor, Lise Getoor, William Yang Wang</li>
<li><b><font class="uci-blue">DesCo: Learning Object Recognition with Rich Language Descriptions</font></b> <br>Liunian Harold Li, Zi-Yi Dou, Nanyun Peng, Kai-Wei Chang</li>
<li><b><font class="uci-blue">Does LLM reasoning support prediction? A case study on self-contradictory reasoning</font></b> <br>Ziyi Liu, Yongkang Du, Isabelle Lee, Soumya Sanyal, Jieyu Zhao</li>
<li><b><font class="uci-blue">STAR: Improving Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models</font></b> <br>Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham, Nanyun Peng, Wei Wang</li>
<li><b><font class="uci-blue">Lumos: Towards Language Agents that are Unified, Modular, and Open Source</font></b> <br>Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin</li>
<li><b><font class="uci-blue">Leveraging Code to Improve In-Context Learning for Semantic Parsing</font></b> <br>Ben Bogin, Shivanshu Gupta, Peter Clark, Ashish Sabharwal</li>
<li><b><font class="uci-blue">LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following</font></b> <br>Cheng-Fu Yang, Kai-Wei Chang</li>
<li><b><font class="uci-blue">Reasoning with language model is planning with world model</font></b> <br>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu</li>
<li><b><font class="uci-blue">Leveraging LLMs for Enhancing User Understanding of Privacy Policies</font></b> <br>Yubo Zhang, Jieyu Zhao</li>
<li><b><font class="uci-blue">Fast Sampling via De-randomization for Discrete Diffusion Models</font></b> <br>Zixiang Chen, Huizhuo Yuan, Yongqian Li, Yiwen Kou, Junkai Zhang, Quanquan Gu</li>
<li><b><font class="uci-blue">How FaR are Large Language Models from Agents with Theory-of-Mind?</font></b> <br>Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R. McKee, Ari Holtzman, Jay Pujara, Xiang Ren, Swaroop Mishra, Aida Nematzadeh, Shyam Upadhyay, Manaal Faruqui</li>
<li><b><font class="uci-blue">ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings</font></b> <br>Shibo Hao, Tianyang Liu, Zhen Wang, Zhiting Hu</li>
<li><b><font class="uci-blue">Are LLMs Effective Negotiators? Evaluating the Multifaceted Capabilities of LLMs in Negotiation Dialogues</font></b> <br>Kushal Chawla, Deuksin Kwon, Emily Weiss, Tara Kulshrestha, Gale Lucas, Jonathan Gratch</li>
<li><b><font class="uci-blue">TRiViS: Visual Instruction Tuning for Text-in-Image Comprehension</font></b> <br>Rohan Wadhawan, Hritik Bansal, Kai-Wei Chang, Nanyun Peng</li>
<li><b><font class="uci-blue">Large Language Models Are Not Robust Multiple Choice Selectors</font></b> <br>Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang</li>
<li><b><font class="uci-blue">EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning</font></b> <br>Raja Sekhar Reddy Mekala, Sameer Singh, Yasaman Razeghi</li>
<li><b><font class="uci-blue">My MacGyver: Are Large Language Models Creative Problem Solvers?</font></b> <br>Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Nanyun Peng, Yejin Choi, Thomas L. Griffiths, Faeze Brahman</li>
<li><b><font class="uci-blue">Deriving Sign Language Phonemes with Neural Discrete Representation Learning</font></b> <br>Lee Kezar, Naomi Caselli, Jesse Thomason</li>
<li><b><font class="uci-blue">Event Detection from Social Media for Epidemic Preparedness</font></b> <br>Tanmay Parekh, Anh Mac, Jiarui Yu, Yuxuan Dong, Syed Shahriar, Bonnie Liu, Eric J Yang, Kuan-Hao Huang, Nanyun Peng, Wei Wang, Kai-Wei Chang</li>

                    </ol></p>
                </div>
            </div>
        </div>
        <br/>


        <div id="organizer" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Organizers</h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h5>General Chairs</h5>
                    <br/>
                </div>

                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                       <a href="https://jyzhao.net/" target="_block">
                           <img src="static/jieyu_zhao.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                       </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://jyzhao.net/" target="_block">Jieyu Zhao</a></b></p>
                    <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>USC</i></p>
                </div>

                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                       <a href="https://robinjia.github.io/" target="_block">
                           <img src="static/robin_jia.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                       </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://robinjia.github.io/" target="_block">Robin Jia</a></b></p>
                    <p class="text-center caption caption-role"><b>Assistant Professor</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>USC</i></p>
                </div>
				
				<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="http://web.cs.ucla.edu/~kwchang/" target="_block">
                            <img src="static/kaiwei_chang.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="http://web.cs.ucla.edu/~kwchang/" target="_block">Kai-Wei Chang</a></b></p>
                    <p class="text-center caption caption-role"><b>Associate Professor</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>
            </div>

            <br/>

            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h5>PC Chairs</h5>
                    <br/>
                </div>
				
				<div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="https://tanmayparekh.github.io/" target="_block">
                            <img src="static/tanmay_parekh.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://tanmayparekh.github.io/" target="_block">Tanmay Parekh</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>
				
                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="https://lupantech.github.io/" target="_block">
                            <img src="static/pan_lu.jpeg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://lupantech.github.io/" target="_block">Pan Lu</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>
            </div>

            <br/>

            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h5>Local Organization Chairs</h5>
                    <br/>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="http://yeqy.xyz/" target="_block">
                            <img src="static/qinyuan_ye.jpeg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="http://yeqy.xyz/" target="_block">Qinyuan Ye</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>USC</i></p>
                </div>

                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                       <a href="https://www.linkedin.com/in/christina-chance-147666166/" target="_block">
                           <img src="static/christina_chance.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                       </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://www.linkedin.com/in/christina-chance-147666166/" target="_block">Christina Chance</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>

                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                       <a href="https://www.linkedin.com/in/masoudmonajatipoor" target="_block">
                           <img src="static/masoud_monajatipoor.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                       </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://www.linkedin.com/in/masoudmonajatipoor" target="_block">Masoud Monajatipoor</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>
            </div>
			
			<br/>
			
			<div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h5>Publicity Chairs</h5>
                    <br/>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="https://brihijoshi.github.io/" target="_block">
                            <img src="static/brihi_joshi.png" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://brihijoshi.github.io/" target="_block">Brihi Joshi</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>USC</i></p>
                </div>
                <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12 thumb">
                    <figure style="margin: auto;" class="rounded">
                        <a href="https://wadeyin9712.github.io/" target="_block">
                            <img src="static/da_yin.jpg" class="img-fluid mx-auto d-block" style="margin-top:-15px"/>
                        </a>
                    </figure>
                    <p class="text-center caption"><b><a href="https://wadeyin9712.github.io/" target="_block">Da Yin</a></b></p>
                    <p class="text-center caption caption-role"><b>Ph.D. Student</b></p>
                    <p class="text-center caption caption-role"><b>Computer Science</b></p>
                    <p class="text-center caption caption-loc"><i>UCLA</i></p>
                </div>
 
            </div>
			

			

        </div>

        <br/>


        <div id="sponsor" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Sponsors </h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                  <h5>Platinum Sponsors</h5> 
                     <br/> 
                    <div class="col-lg-3 col-md-3 col-sm-2 col-xs-2 thumb" style="float:left;">
                        <a href="https://www.sciencehub.ucla.edu/" target="_block"><img src="static/Science-hub-logo.png" class="rounded img-fluid mx-auto d-block" style="height:7rem;"/></a>
                    </div>
                    <div class="col-lg-2 col-md-2 col-sm-2 col-xs-2 thumb" style="float:left;">
                        <a href="https://www.capitalone.com/tech/" target="_block"><img src="static/captalone_logo.png" class="rounded img-fluid mx-auto d-block" style="height:7rem;"/></a>
                    </div>
                    <div class="col-lg-3 col-md-4 col-sm-4 col-xs-8 thumb" style="float:left;">
                        <a href="https://icn.sap.com/" target="_block"><img src="static/sap_logo.png" class="rounded img-fluid mx-auto d-block" style="height:5rem;"/></a>
                    </div>
		</div>
		  <br/>
		<div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
		  <h5>Gold Sponsors</h5> 
			<div class="col-lg-2 col-md-2 col-sm-2 col-xs-2 thumb" style="float:left;">
                        <a href="https://new.nsf.gov/" target="_block"><img src="static/NSF_logo.png" class="rounded img-fluid mx-auto d-block" style="height:7rem;"/></a>
                    </div>
		
		</div>
		    	 <br/>
		<div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
		   <h5>The symposium venue is sponsored by</h5> 
			<div class="col-lg-3 col-md-4 col-sm-4 col-xs-8 thumb" style="float:left;">
                        <a href="https://samueli.ucla.edu/" target="_block"><img src="static/ucla-samueli-logo.png" class="rounded img-fluid mx-auto d-block" style="height:5rem;"/></a>
                    </div>
		</div>
<!--                     <h5> </h5>
                    <div class="col-lg-3 col-md-4 col-sm-4 col-xs-8 thumb" style="float:left;">
                        <a href="https://icn.sap.com/" target="_block"><img src="static/SAP.png" class="rounded img-fluid mx-auto d-block" style="height:5rem;"/></a>
                    </div> -->
                </div>
		    <!-- 
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <br/>
                    <h5>Silver Sponsors</h5> 
                    <br/>
                    <div class="col-lg-2 col-md-2 col-sm-2 col-xs-2 thumb" style="float:left;">
                        <a href="http://kwchang.net" target="_block"><img src="static/uclanlp_logo.png" class="rounded img-fluid mx-auto d-block" style="height:5rem;"/></a>
                    </div>
                </div> -->
                <!-- <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <br/>
                    <h5>Bronze Sponsors</h5>
                    <br/>
                     <div class="col-lg-4 col-md-6 col-sm-6 col-xs-12 thumb" style="float:left;">
                        <a href="http://ir.baidu.com/phoenix.zhtml?c=188488&p=irol-irhome" target="_block"><img src="static/baidu.png" class="rounded img-fluid mx-auto d-block"/></a>
                    </div>
                    <br/>
                     <div class="col-lg-4 col-md-6 col-sm-6 col-xs-12 thumb" style="float:left;">
                        <a href="https://facebook.com" target="_block"><img src="static/facebook.png" class="rounded img-fluid mx-auto d-block"/></a>
                    </div>
                </div> -->
            </div>
        </div>

        <br/>
</div>
        <div id="past" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Past Symposiums</h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <p>
                        <a href="../symp18/index.html" target="_blank">SoCal NLP Symposium 2018</a>
                    </p>
                    <p>
                        <a href="../symp19/index.html" target="_blank">SoCal NLP Symposium 2019</a>
                    </p>
                    <p>
                        <a href="https://cseweb.ucsd.edu/~jmcauley/workshops/scmls20/" target="_blank">SoCal ML Symposium 2020 (cancelled, merged SoCal ML&NLP 2021)</a>
                    </p>
                    <p>
                        <a href="../symp21/index.html" target="_blank">SoCal ML & NLP Symposium 2021</a>
                    </p>
					<p>
                        <a href="../symp22/index.html" target="_blank">SoCal NLP Symposium 2022</a>
                    </p>
                </div>
            </div>
        </div>

        <br/>

        <div id="contact" class="container" align="justify">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <h4>Contact</h4>
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <p>
                        Please feel free to forward this message to those who might be interested. If you have questions, please contact us at <a href="mailto:socalnlp23@googlegroups.com">socalnlp23@googlegroups.com</a>.
                    </p>
                </div>
            </div>
        </div>

        <br/>
        <hr>

        <div class="container footer">
            <div class="row">
                <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
                    <p align="left">
                        Copyright &copy; SoCal NLP Symposium 2023<br/>
                        <!-- Cover photo from  <a href="https://twitter.com/UCSDalumni/status/1340121401005522944/photo/1" target="_blank">@UCSDalumni tweet | Erik Jepsen</a> -->
                    </p>
                </div>
            </div>
        </div>
    </body>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')</script>
    <script src="js/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
</html>
